# -*- coding: utf-8 -*-
"""Pupil_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ExaScBnzMlL8bmdaNXNzEHoO2Fc6vGay
"""

'''!pip install kaggle
from google.colab import files
files.upload()
!mkdir ~/.kaggle
#!cp -r kaggle.json ~/ .kaggle/
!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json
!chmod 600 ~/ .kaggle/kaggle.json
!kaggle competitions download -c facial-keypoints-detection'''

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# Start Python Imports
import math, time, random, datetime

# Data Manipulation
import numpy as np
import pandas as pd

# Visualization 
import matplotlib.pyplot as plt
import missingno
import seaborn as sns
plt.style.use('seaborn-whitegrid')
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize

# Machine learning
!pip install catboost
import catboost
from sklearn.model_selection import train_test_split
from sklearn import model_selection, tree, preprocessing, metrics, linear_model
from sklearn.svm import LinearSVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from catboost import CatBoostClassifier, Pool, cv
from sklearn.preprocessing import StandardScaler
from keras.layers.advanced_activations import ReLU
from keras.models import Sequential, Model
from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D

import warnings
warnings.filterwarnings('ignore')

train=pd.read_csv("training[1].csv")
len(train['Image'][1])
#display(train.isnull().sum())
train.fillna(method = 'ffill',inplace = True)
#display(train.isnull().sum())

Vis = []

for i in range(len(train)-5):
  Vis.append(train['Image'][i].split(' '))
 # print(Vis[i])


Vis = np.array(Vis, dtype='float')

X_train = Vis.reshape(-1,96,96,1)
photo_visualize = Vis[15].reshape(96,96)
plt.imshow(photo_visualize, cmap='gray')

y_train = []
for i in range(len(train)-5):
    y = train['left_eye_center_x'][i]
    y_train.append(y)
   
    
X_train=np.asarray(X_train)
y_train=np.asarray(y_train)

model = Sequential()


# layer 1
model.add(Convolution2D(32, (3,3), activation = 'relu', padding='same', use_bias=False, input_shape=(96,96,1)))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))

# layer 2

model.add(Convolution2D(32, (3,3), activation = 'relu', padding='same', use_bias=False))
model.add(MaxPool2D(pool_size=(2, 2)))

# layer 3

model.add(Convolution2D(64, (3,3), activation = 'relu', padding='same', use_bias=False))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))

# layer 4

model.add(Convolution2D(128, (3,3), activation = 'relu', padding='same', use_bias=False))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))


model.add(Flatten())
model.add(Dense(256,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1))

model.compile(optimizer='adam', 
              loss='mean_squared_error',
              metrics=['acc'])

model.fit(X_train,y_train,epochs = 5,batch_size = len(train)-5,validation_split = 0.2)
model.predict(X_train[1:5])